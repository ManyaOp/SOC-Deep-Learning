{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "## Logistic Regression \n",
    "Logistic Regression is a fundamental supervised learning algorithm used for binary classification tasks. Despite its name, it's used for classification, not regression. Logistic Regression models the probability that a given input belongs to a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Steps\n",
    "1. Data Pre-processing\n",
    "2. Parameter Initialization\n",
    "3. Forward Propagation:\n",
    "4. Cost Calculation\n",
    "5. Backward Propagation\n",
    "6. Parameter Update\n",
    "7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import libraries we've already learnt and will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Pre-Processing\n",
    "The dataset contains information that may be used for diagnosing or predicting the presence of heart disease in individuals. It comprises various clinical and demographic features that are commonly considered in cardiovascular health assessment. Understanding and analyzing these features can aid in developing predictive models or understanding the factors associated with heart disease.  \n",
    "The first 13 fields are \n",
    "- Age\n",
    "- Sex\n",
    "- Chest Pain Type (cp)\n",
    "- Resting Blood Pressure (trestbps)\n",
    "- Serum Cholesterol Level (chol)\n",
    "- Fasting Blood Sugar (fbs)\n",
    "- Resting Electrocardiographic Results (restecg)\n",
    "- Maximum Heart Rate Achieved (thalach)\n",
    "- Exercise-Induced Angina (exang)\n",
    "- ST Depression Induced by Exercise Relative to Rest (oldpeak)\n",
    "- Slope of the Peak Exercise ST Segment (slope)\n",
    "- Number of Major Vessels Colored by Fluoroscopy (ca)\n",
    "- Thalassemia (thal)  \n",
    "\n",
    "And the 14th field is 'target' and is either 0 or 1. The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import data from the csv file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1026, 14)\n"
     ]
    }
   ],
   "source": [
    "dataset_raw = np.genfromtxt(\"./dataset/heart.csv\", dtype=\"str\", delimiter=\",\")\n",
    "print(dataset_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset have headers that we don't need for logistic regression model. That is there for us to understand what the values denote  \n",
    "We seperate the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'sex' 'cp' 'trestbps' 'chol' 'fbs' 'restecg' 'thalach' 'exang'\n",
      " 'oldpeak' 'slope' 'ca' 'thal' 'target']\n"
     ]
    }
   ],
   "source": [
    "headers = dataset_raw[0, :]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we get rest of the numerical data and cast them as `float` data type instead of `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52.  1.  0. ...  2.  3.  0.]\n",
      " [53.  1.  0. ...  0.  3.  0.]\n",
      " [70.  1.  0. ...  0.  3.  0.]\n",
      " ...\n",
      " [47.  1.  0. ...  1.  2.  0.]\n",
      " [50.  0.  0. ...  0.  2.  1.]\n",
      " [54.  1.  0. ...  1.  3.  0.]]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_raw[1:, :]\n",
    "dataset = dataset.astype(float)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the first 13 columns represent the features, while the 14th column indicates whether the individual has the disease or not based on those features. Here we seperate the dataset into X (feature vector) and Y (output vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 13)\n",
      "(1025,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:, :13]\n",
    "Y = dataset[:, 13]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of X here is $(m, n_x)$, but we want it to have $shape = (n_x, m)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 1025)\n",
      "(1025,)\n"
     ]
    }
   ],
   "source": [
    "X = X.T\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks good\n",
    "Finally, we have 1025 examples of 13 features and 1 output  \n",
    "From the notation you have studied till now  \n",
    "$$\n",
    "\\begin{align*}\n",
    "n_x &= 13 \\\\\n",
    "n_y &= 1 \\\\\n",
    "m &= 1025\n",
    "\\end{align*}\n",
    "$$\n",
    "Now we can proceed to making our logistic regression model and train our model  \n",
    "But, we have one problem to deal with. How would we know if our model is doing good and if it is, how good is it?  \n",
    "That is why from the 1025 examples we have, we'll keep some data aside and use it to test our model's prediction  \n",
    "Let's keep 80% of the data for training and 20% of the data for testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index to split data in 80:20 ratio\n",
    "index = int(0.8 * X.shape[1])\n",
    "\n",
    "# split the data\n",
    "X_train = X[:, :index]\n",
    "X_test = X[:, index:]\n",
    "\n",
    "Y_train = Y[:index]\n",
    "Y_test = Y[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print shapes for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (13, 820)\n",
      "Y_train shape (820,)\n",
      "Number of training examples = 820\n",
      "----------------------------------------\n",
      "X_test shape (13, 205)\n",
      "Y_test shape (205,)\n",
      "Number of testing examples = 205\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"Number of training examples =\", Y_train.shape[0])\n",
    "print(\"-\"*40)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_test shape\", Y_test.shape)\n",
    "print(\"Number of testing examples =\", Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "#### Forward Propagation\n",
    "$$\n",
    "Z = W^T X + b  \\\\\n",
    "A = sigmoid(X) \\\\\n",
    "$$\n",
    "#### Calculate Cost\n",
    "$$\n",
    "J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\n",
    "$$\n",
    "#### Backward Propagation\n",
    "$$ \\partial W = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\partial b = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n",
    "#### Parameter Updation\n",
    "$$ W = W - \\alpha \\text{ } \\partial W $$\n",
    "$$ b = b - \\alpha \\text{ } \\partial b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initializing parameters\n",
    "**Assignment**: Complete the function for parameter initialization in the cell below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(num_features):\n",
    "\n",
    "  \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "  \n",
    "    Returns:\n",
    "    W -- initialized vector of shape (num_features, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "  \"\"\"\n",
    "\n",
    "  W = np.zeros(num_features)\n",
    "  b = 0\n",
    "\n",
    "  return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Function**: Sigmoid\n",
    "**Assignment**: Complete the function for calculating sigmoid in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "  \"\"\"\n",
    "  \n",
    "  s = 1/(1+np.exp(-x))\n",
    "\n",
    "  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Forward Propagation\n",
    "$$\n",
    "Z = W^T X + b  \\\\\n",
    "A = sigmoid(X) \\\\\n",
    "$$\n",
    "**Assignment**: Complete the function implementing forward propagation in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W, b, X):\n",
    "  \"\"\"\n",
    "    Compute forward propagation\n",
    "\n",
    "    Return:\n",
    "    A -- activation\n",
    "  \"\"\"\n",
    "\n",
    "  # forward propagation\n",
    "  Z = np.dot(W,X)\n",
    "  A = sigmoid(Z)\n",
    "  \n",
    "  return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate Cost\n",
    "$$\n",
    "J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\n",
    "$$\n",
    "**Assignment**: Complete the function to calculate cost in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(A, Y):\n",
    "  \"\"\"\n",
    "    Calculate cross entropy loss between calculated values (A) and actual values (Y)\n",
    "\n",
    "    Return:\n",
    "    cost -- cost calculated\n",
    "  \"\"\"\n",
    "\n",
    "  # get number of examples\n",
    "  m = Y.shape\n",
    "\n",
    "  # calculate cost\n",
    "  cost = -(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))/m\n",
    "\n",
    "  # this will remove any useless dimensions from cost\n",
    "  # not doing this might give us an array instead of a single value\n",
    "  cost = np.squeeze(cost)\n",
    "\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Backward Propagation\n",
    "$$ \\partial W = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\partial b = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n",
    "**Assignment**: Complete the function to compute gradients in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(A, X, Y):\n",
    "  \"\"\"\n",
    "    Calculate gradients dW and db\n",
    "\n",
    "    Return:\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "  \"\"\"\n",
    "\n",
    "  # get number of examples\n",
    "  m = Y.shape\n",
    "\n",
    "  # calculate gradients\n",
    "  dW = np.dot(X,A-Y)/m \n",
    "  db = np.sum(A-Y)/m\n",
    "\n",
    "  return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Parameter Updation\n",
    "$$ W = W - \\alpha \\text{ } \\partial W $$\n",
    "$$ b = b - \\alpha \\text{ } \\partial b $$\n",
    "**Assignment**: Complete the function to update parameters in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W, b, dW, db, learning_rate):\n",
    "  \"\"\"\n",
    "    Update params W and b from their gradients\n",
    "\n",
    "    Return:\n",
    "    W -- updated W\n",
    "    b -- updated b\n",
    "  \"\"\"\n",
    "\n",
    "  W = W-learning_rate*dW\n",
    "  b = b-db*learning_rate\n",
    "\n",
    "  return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our model's forward propagation return value calculated from sigmoid function, it lies between 0 and 1  \n",
    "We can say output should be 1 when A > 0.5 and 0 when A < 0.5  \n",
    "Let's implement a function that will do this for us in vectorized way\n",
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X):\n",
    "  A = forward_prop(W, b, X)\n",
    "  Y_pred = (A>=0.5)*1.0\n",
    "  return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compile all these function to implement training loop for our model\n",
    "You don't need to write any math here, just put all the functions you've written above in the right sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, num_iterations=100000, learning_rate=0.0001, print_cost=True):\n",
    "  # initialize parameters\n",
    "  W, b = init_params(13)\n",
    "\n",
    "  # let's keep track of our cost to see how our model\n",
    "  # reduces cost after every few iteration\n",
    "  costs = []\n",
    "\n",
    "  for i in range(num_iterations):\n",
    "\n",
    "    # forward propagation\n",
    "    A = forward_prop(W, b, X)\n",
    "\n",
    "    # calculate cost\n",
    "    cost = calculate_loss(A,Y)\n",
    "\n",
    "    # backward propagation\n",
    "    dW, db = backward_prop(A, X, Y)\n",
    "\n",
    "    # parameter updation\n",
    "    W, b = update_params(W, b, dW, db, learning_rate)\n",
    "\n",
    "    # store cost after every few iterations\n",
    "    if i%100 == 0:\n",
    "      costs.append(cost)\n",
    "\n",
    "    # print cost after every few iterations\n",
    "    if print_cost and i%100 == 0:\n",
    "      print(f\"Cost after {i+1} iteration : {cost}\")\n",
    "    \n",
    "  return W, b, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let the model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 1 iteration : 0.6931471805599453\n",
      "Cost after 101 iteration : 0.7723553770952422\n",
      "Cost after 201 iteration : 0.6739846267483204\n",
      "Cost after 301 iteration : 0.6417748077847988\n",
      "Cost after 401 iteration : 0.6285804618819946\n",
      "Cost after 501 iteration : 0.6229349235796643\n",
      "Cost after 601 iteration : 0.6201634168554236\n",
      "Cost after 701 iteration : 0.6184393368380338\n",
      "Cost after 801 iteration : 0.6170958143968744\n",
      "Cost after 901 iteration : 0.6158965562150402\n",
      "Cost after 1001 iteration : 0.6147581477443302\n",
      "Cost after 1101 iteration : 0.6136506241250104\n",
      "Cost after 1201 iteration : 0.6125626445842071\n",
      "Cost after 1301 iteration : 0.6114893917241375\n",
      "Cost after 1401 iteration : 0.6104283809507335\n",
      "Cost after 1501 iteration : 0.6093780103057362\n",
      "Cost after 1601 iteration : 0.6083370566506945\n",
      "Cost after 1701 iteration : 0.6073044976044966\n",
      "Cost after 1801 iteration : 0.606279445191926\n",
      "Cost after 1901 iteration : 0.6052611176760602\n",
      "Cost after 2001 iteration : 0.6042488244831942\n",
      "Cost after 2101 iteration : 0.6032419557582206\n",
      "Cost after 2201 iteration : 0.6022399737568108\n",
      "Cost after 2301 iteration : 0.6012424051858279\n",
      "Cost after 2401 iteration : 0.600248834225076\n",
      "Cost after 2501 iteration : 0.5992588961533917\n",
      "Cost after 2601 iteration : 0.598272271550949\n",
      "Cost after 2701 iteration : 0.597288681055619\n",
      "Cost after 2801 iteration : 0.5963078806464495\n",
      "Cost after 2901 iteration : 0.5953296574217485\n",
      "Cost after 3001 iteration : 0.5943538258354734\n",
      "Cost after 3101 iteration : 0.5933802243538617\n",
      "Cost after 3201 iteration : 0.5924087124940993\n",
      "Cost after 3301 iteration : 0.5914391682078918\n",
      "Cost after 3401 iteration : 0.5904714855746487\n",
      "Cost after 3501 iteration : 0.5895055727712899\n",
      "Cost after 3601 iteration : 0.5885413502882463\n",
      "Cost after 3701 iteration : 0.5875787493638609\n",
      "Cost after 3801 iteration : 0.5866177106120024\n",
      "Cost after 3901 iteration : 0.5856581828202194\n",
      "Cost after 4001 iteration : 0.5847001218981288\n",
      "Cost after 4101 iteration : 0.5837434899579266\n",
      "Cost after 4201 iteration : 0.5827882545109299\n",
      "Cost after 4301 iteration : 0.581834387765904\n",
      "Cost after 4401 iteration : 0.5808818660165586\n",
      "Cost after 4501 iteration : 0.5799306691071318\n",
      "Cost after 4601 iteration : 0.5789807799662556\n",
      "Cost after 4701 iteration : 0.5780321842005394\n",
      "Cost after 4801 iteration : 0.5770848697403049\n",
      "Cost after 4901 iteration : 0.5761388265308761\n",
      "Cost after 5001 iteration : 0.5751940462636338\n",
      "Cost after 5101 iteration : 0.5742505221417535\n",
      "Cost after 5201 iteration : 0.573308248676213\n",
      "Cost after 5301 iteration : 0.5723672215081831\n",
      "Cost after 5401 iteration : 0.5714274372544267\n",
      "Cost after 5501 iteration : 0.570488893372749\n",
      "Cost after 5601 iteration : 0.5695515880449203\n",
      "Cost after 5701 iteration : 0.5686155200748281\n",
      "Cost after 5801 iteration : 0.5676806887998924\n",
      "Cost after 5901 iteration : 0.5667470940140348\n",
      "Cost after 6001 iteration : 0.5658147359007156\n",
      "Cost after 6101 iteration : 0.5648836149747328\n",
      "Cost after 6201 iteration : 0.5639537320316566\n",
      "Cost after 6301 iteration : 0.5630250881039114\n",
      "Cost after 6401 iteration : 0.5620976844226488\n",
      "Cost after 6501 iteration : 0.5611715223846562\n",
      "Cost after 6601 iteration : 0.560246603523663\n",
      "Cost after 6701 iteration : 0.5593229294854596\n",
      "Cost after 6801 iteration : 0.558400502006356\n",
      "Cost after 6901 iteration : 0.557479322894528\n",
      "Cost after 7001 iteration : 0.5565593940139013\n",
      "Cost after 7101 iteration : 0.5556407172702204\n",
      "Cost after 7201 iteration : 0.5547232945990492\n",
      "Cost after 7301 iteration : 0.5538071279554293\n",
      "Cost after 7401 iteration : 0.5528922193050047\n",
      "Cost after 7501 iteration : 0.5519785706164075\n",
      "Cost after 7601 iteration : 0.5510661838547601\n",
      "Cost after 7701 iteration : 0.5501550609761408\n",
      "Cost after 7801 iteration : 0.5492452039228952\n",
      "Cost after 7901 iteration : 0.5483366146196922\n",
      "Cost after 8001 iteration : 0.5474292949702232\n",
      "Cost after 8101 iteration : 0.5465232468544763\n",
      "Cost after 8201 iteration : 0.5456184721265102\n",
      "Cost after 8301 iteration : 0.5447149726126673\n",
      "Cost after 8401 iteration : 0.5438127501101826\n",
      "Cost after 8501 iteration : 0.5429118063861401\n",
      "Cost after 8601 iteration : 0.5420121431767388\n",
      "Cost after 8701 iteration : 0.5411137621868396\n",
      "Cost after 8801 iteration : 0.5402166650897658\n",
      "Cost after 8901 iteration : 0.5393208535273355\n",
      "Cost after 9001 iteration : 0.5384263291101095\n",
      "Cost after 9101 iteration : 0.5375330934178355\n",
      "Cost after 9201 iteration : 0.536641148000084\n",
      "Cost after 9301 iteration : 0.5357504943770657\n",
      "Cost after 9401 iteration : 0.5348611340406233\n",
      "Cost after 9501 iteration : 0.5339730684553977\n",
      "Cost after 9601 iteration : 0.5330862990601695\n",
      "Cost after 9701 iteration : 0.5322008272693749\n",
      "Cost after 9801 iteration : 0.5313166544748116\n",
      "Cost after 9901 iteration : 0.5304337820475216\n",
      "Cost after 10001 iteration : 0.5295522113398892\n",
      "Cost after 10101 iteration : 0.5286719436879449\n",
      "Cost after 10201 iteration : 0.5277929804139038\n",
      "Cost after 10301 iteration : 0.5269153228289497\n",
      "Cost after 10401 iteration : 0.5260389722363006\n",
      "Cost after 10501 iteration : 0.525163929934566\n",
      "Cost after 10601 iteration : 0.5242901972214417\n",
      "Cost after 10701 iteration : 0.5234177753977691\n",
      "Cost after 10801 iteration : 0.5225466657720037\n",
      "Cost after 10901 iteration : 0.5216768696651439\n",
      "Cost after 11001 iteration : 0.5208083884161672\n",
      "Cost after 11101 iteration : 0.5199412233880477\n",
      "Cost after 11201 iteration : 0.5190753759744141\n",
      "Cost after 11301 iteration : 0.5182108476069487\n",
      "Cost after 11401 iteration : 0.517347639763609\n",
      "Cost after 11501 iteration : 0.5164857539777915\n",
      "Cost after 11601 iteration : 0.5156251918485703\n",
      "Cost after 11701 iteration : 0.5147659550521473\n",
      "Cost after 11801 iteration : 0.5139080453547029\n",
      "Cost after 11901 iteration : 0.5130514646268464\n",
      "Cost after 12001 iteration : 0.5121962148598933\n",
      "Cost after 12101 iteration : 0.5113422981842611\n",
      "Cost after 12201 iteration : 0.5104897168903\n",
      "Cost after 12301 iteration : 0.5096384734519485\n",
      "Cost after 12401 iteration : 0.5087885705536626\n",
      "Cost after 12501 iteration : 0.5079400111211566\n",
      "Cost after 12601 iteration : 0.5070927983565973\n",
      "Cost after 12701 iteration : 0.5062469357790106\n",
      "Cost after 12801 iteration : 0.5054024272708102\n",
      "Cost after 12901 iteration : 0.5045592771315479\n",
      "Cost after 13001 iteration : 0.5037174901402108\n",
      "Cost after 13101 iteration : 0.5028770716276524\n",
      "Cost after 13201 iteration : 0.5020380275611197\n",
      "Cost after 13301 iteration : 0.5012003646432501\n",
      "Cost after 13401 iteration : 0.5003640904284499\n",
      "Cost after 13501 iteration : 0.4995292134602659\n",
      "Cost after 13601 iteration : 0.4986957434342013\n",
      "Cost after 13701 iteration : 0.49786369139153924\n",
      "Cost after 13801 iteration : 0.4970330699511238\n",
      "Cost after 13901 iteration : 0.4962038935878743\n",
      "Cost after 14001 iteration : 0.4953761789691272\n",
      "Cost after 14101 iteration : 0.4945499453629581\n",
      "Cost after 14201 iteration : 0.4937252151366454\n",
      "Cost after 14301 iteration : 0.4929020143687069\n",
      "Cost after 14401 iteration : 0.49208037360499324\n",
      "Cost after 14501 iteration : 0.4912603287987418\n",
      "Cost after 14601 iteration : 0.49044192248723667\n",
      "Cost after 14701 iteration : 0.4896252052750385\n",
      "Cost after 14801 iteration : 0.48881023771751664\n",
      "Cost after 14901 iteration : 0.4879970927312162\n",
      "Cost after 15001 iteration : 0.4871858587032946\n",
      "Cost after 15101 iteration : 0.4863766435362818\n",
      "Cost after 15201 iteration : 0.4855695799548172\n",
      "Cost after 15301 iteration : 0.4847648325292897\n",
      "Cost after 15401 iteration : 0.4839626070541725\n",
      "Cost after 15501 iteration : 0.4831631631800078\n",
      "Cost after 15601 iteration : 0.48236683157039034\n",
      "Cost after 15701 iteration : 0.4815740373824161\n",
      "Cost after 15801 iteration : 0.48078533260272177\n",
      "Cost after 15901 iteration : 0.4800014407585919\n",
      "Cost after 16001 iteration : 0.47922331876611884\n",
      "Cost after 16101 iteration : 0.47845224202375275\n",
      "Cost after 16201 iteration : 0.4776899197541551\n",
      "Cost after 16301 iteration : 0.4769386465435705\n",
      "Cost after 16401 iteration : 0.47620148957994224\n",
      "Cost after 16501 iteration : 0.47548249236128515\n",
      "Cost after 16601 iteration : 0.47478683339727124\n",
      "Cost after 16701 iteration : 0.47412080130300416\n",
      "Cost after 16801 iteration : 0.4734913450083597\n",
      "Cost after 16901 iteration : 0.4729049098383149\n",
      "Cost after 17001 iteration : 0.47236547690813663\n",
      "Cost after 17101 iteration : 0.47187238474584453\n",
      "Cost after 17201 iteration : 0.4714193427791863\n",
      "Cost after 17301 iteration : 0.47099593187941446\n",
      "Cost after 17401 iteration : 0.47059110113602054\n",
      "Cost after 17501 iteration : 0.4701963342069312\n",
      "Cost after 17601 iteration : 0.4698066650142254\n",
      "Cost after 17701 iteration : 0.4694198517488772\n",
      "Cost after 17801 iteration : 0.4690350949329016\n",
      "Cost after 17901 iteration : 0.4686521621419599\n",
      "Cost after 18001 iteration : 0.4682709927071596\n",
      "Cost after 18101 iteration : 0.46789156696593653\n",
      "Cost after 18201 iteration : 0.4675138731269894\n",
      "Cost after 18301 iteration : 0.4671379006733887\n",
      "Cost after 18401 iteration : 0.4667636393136711\n",
      "Cost after 18501 iteration : 0.46639107884618647\n",
      "Cost after 18601 iteration : 0.4660202091437431\n",
      "Cost after 18701 iteration : 0.46565102015122045\n",
      "Cost after 18801 iteration : 0.46528350188446393\n",
      "Cost after 18901 iteration : 0.46491764442939226\n",
      "Cost after 19001 iteration : 0.46455343794121223\n",
      "Cost after 19101 iteration : 0.46419087264370784\n",
      "Cost after 19201 iteration : 0.4638299388285882\n",
      "Cost after 19301 iteration : 0.463470626854877\n",
      "Cost after 19401 iteration : 0.4631129271483372\n",
      "Cost after 19501 iteration : 0.46275683020091973\n",
      "Cost after 19601 iteration : 0.4624023265702335\n",
      "Cost after 19701 iteration : 0.4620494068790303\n",
      "Cost after 19801 iteration : 0.46169806181470274\n",
      "Cost after 19901 iteration : 0.46134828212879236\n",
      "Cost after 20001 iteration : 0.4610000586365066\n",
      "Cost after 20101 iteration : 0.460653382216242\n",
      "Cost after 20201 iteration : 0.4603082438091146\n",
      "Cost after 20301 iteration : 0.4599646344184951\n",
      "Cost after 20401 iteration : 0.45962254510954853\n",
      "Cost after 20501 iteration : 0.45928196700877916\n",
      "Cost after 20601 iteration : 0.4589428913035784\n",
      "Cost after 20701 iteration : 0.45860530924177734\n",
      "Cost after 20801 iteration : 0.45826921213120203\n",
      "Cost after 20901 iteration : 0.45793459133923287\n",
      "Cost after 21001 iteration : 0.45760143829236716\n",
      "Cost after 21101 iteration : 0.4572697444757843\n",
      "Cost after 21201 iteration : 0.4569395014329144\n",
      "Cost after 21301 iteration : 0.456610700765011\n",
      "Cost after 21401 iteration : 0.45628333413072486\n",
      "Cost after 21501 iteration : 0.4559573932456822\n",
      "Cost after 21601 iteration : 0.45563286988206536\n",
      "Cost after 21701 iteration : 0.45530975586819705\n",
      "Cost after 21801 iteration : 0.45498804308812607\n",
      "Cost after 21901 iteration : 0.45466772348121715\n",
      "Cost after 22001 iteration : 0.45434878904174375\n",
      "Cost after 22101 iteration : 0.4540312318184827\n",
      "Cost after 22201 iteration : 0.45371504391431255\n",
      "Cost after 22301 iteration : 0.4534002174858143\n",
      "Cost after 22401 iteration : 0.4530867447428752\n",
      "Cost after 22501 iteration : 0.4527746179482948\n",
      "Cost after 22601 iteration : 0.4524638294173952\n",
      "Cost after 22701 iteration : 0.4521543715176317\n",
      "Cost after 22801 iteration : 0.4518462366682088\n",
      "Cost after 22901 iteration : 0.45153941733969677\n",
      "Cost after 23001 iteration : 0.4512339060536525\n",
      "Cost after 23101 iteration : 0.45092969538224226\n",
      "Cost after 23201 iteration : 0.45062677794786693\n",
      "Cost after 23301 iteration : 0.45032514642279137\n",
      "Cost after 23401 iteration : 0.450024793528774\n",
      "Cost after 23501 iteration : 0.4497257120367018\n",
      "Cost after 23601 iteration : 0.44942789476622585\n",
      "Cost after 23701 iteration : 0.4491313345854002\n",
      "Cost after 23801 iteration : 0.4488360244103243\n",
      "Cost after 23901 iteration : 0.4485419572047862\n",
      "Cost after 24001 iteration : 0.4482491259799097\n",
      "Cost after 24101 iteration : 0.4479575237938039\n",
      "Cost after 24201 iteration : 0.44766714375121497\n",
      "Cost after 24301 iteration : 0.44737797900318044\n",
      "Cost after 24401 iteration : 0.4470900227466866\n",
      "Cost after 24501 iteration : 0.4468032682243276\n",
      "Cost after 24601 iteration : 0.44651770872396773\n",
      "Cost after 24701 iteration : 0.4462333375784062\n",
      "Cost after 24801 iteration : 0.4459501481650439\n",
      "Cost after 24901 iteration : 0.4456681339055527\n",
      "Cost after 25001 iteration : 0.4453872882655478\n",
      "Cost after 25101 iteration : 0.44510760475426214\n",
      "Cost after 25201 iteration : 0.4448290769242228\n",
      "Cost after 25301 iteration : 0.4445516983709308\n",
      "Cost after 25401 iteration : 0.44427546273254215\n",
      "Cost after 25501 iteration : 0.4440003636895526\n",
      "Cost after 25601 iteration : 0.44372639496448313\n",
      "Cost after 25701 iteration : 0.4434535503215695\n",
      "Cost after 25801 iteration : 0.4431818235664532\n",
      "Cost after 25901 iteration : 0.44291120854587424\n",
      "Cost after 26001 iteration : 0.44264169914736773\n",
      "Cost after 26101 iteration : 0.4423732892989612\n",
      "Cost after 26201 iteration : 0.4421059729688754\n",
      "Cost after 26301 iteration : 0.4418397441652268\n",
      "Cost after 26401 iteration : 0.44157459693573203\n",
      "Cost after 26501 iteration : 0.44131052536741566\n",
      "Cost after 26601 iteration : 0.44104752358631877\n",
      "Cost after 26701 iteration : 0.44078558575721094\n",
      "Cost after 26801 iteration : 0.4405247060833035\n",
      "Cost after 26901 iteration : 0.4402648788059662\n",
      "Cost after 27001 iteration : 0.4400060982044446\n",
      "Cost after 27101 iteration : 0.43974835859558026\n",
      "Cost after 27201 iteration : 0.4394916543335334\n",
      "Cost after 27301 iteration : 0.43923597980950724\n",
      "Cost after 27401 iteration : 0.4389813294514748\n",
      "Cost after 27501 iteration : 0.43872769772390713\n",
      "Cost after 27601 iteration : 0.43847507912750444\n",
      "Cost after 27701 iteration : 0.4382234681989289\n",
      "Cost after 27801 iteration : 0.43797285951053927\n",
      "Cost after 27901 iteration : 0.4377232476701278\n",
      "Cost after 28001 iteration : 0.43747462732065995\n",
      "Cost after 28101 iteration : 0.4372269931400141\n",
      "Cost after 28201 iteration : 0.4369803398407257\n",
      "Cost after 28301 iteration : 0.43673466216973106\n",
      "Cost after 28401 iteration : 0.4364899549081155\n",
      "Cost after 28501 iteration : 0.436246212870861\n",
      "Cost after 28601 iteration : 0.4360034309065978\n",
      "Cost after 28701 iteration : 0.435761603897357\n",
      "Cost after 28801 iteration : 0.43552072675832487\n",
      "Cost after 28901 iteration : 0.43528079443759976\n",
      "Cost after 29001 iteration : 0.43504180191595015\n",
      "Cost after 29101 iteration : 0.43480374420657547\n",
      "Cost after 29201 iteration : 0.43456661635486765\n",
      "Cost after 29301 iteration : 0.43433041343817547\n",
      "Cost after 29401 iteration : 0.43409513056557064\n",
      "Cost after 29501 iteration : 0.4338607628776149\n",
      "Cost after 29601 iteration : 0.43362730554612977\n",
      "Cost after 29701 iteration : 0.4333947537739675\n",
      "Cost after 29801 iteration : 0.433163102794785\n",
      "Cost after 29901 iteration : 0.4329323478728173\n",
      "Cost after 30001 iteration : 0.4327024843026554\n",
      "Cost after 30101 iteration : 0.4324735074090234\n",
      "Cost after 30201 iteration : 0.43224541254655946\n",
      "Cost after 30301 iteration : 0.43201819509959677\n",
      "Cost after 30401 iteration : 0.43179185048194757\n",
      "Cost after 30501 iteration : 0.43156637413668797\n",
      "Cost after 30601 iteration : 0.4313417615359447\n",
      "Cost after 30701 iteration : 0.4311180081806838\n",
      "Cost after 30801 iteration : 0.4308951096005003\n",
      "Cost after 30901 iteration : 0.43067306135341044\n",
      "Cost after 31001 iteration : 0.4304518590256448\n",
      "Cost after 31101 iteration : 0.4302314982314432\n",
      "Cost after 31201 iteration : 0.43001197461285134\n",
      "Cost after 31301 iteration : 0.4297932838395191\n",
      "Cost after 31401 iteration : 0.42957542160849993\n",
      "Cost after 31501 iteration : 0.4293583836440528\n",
      "Cost after 31601 iteration : 0.42914216569744434\n",
      "Cost after 31701 iteration : 0.4289267635467537\n",
      "Cost after 31801 iteration : 0.4287121729966782\n",
      "Cost after 31901 iteration : 0.42849838987834066\n",
      "Cost after 32001 iteration : 0.42828541004909915\n",
      "Cost after 32101 iteration : 0.42807322939235637\n",
      "Cost after 32201 iteration : 0.4278618438173723\n",
      "Cost after 32301 iteration : 0.4276512492590774\n",
      "Cost after 32401 iteration : 0.42744144167788695\n",
      "Cost after 32501 iteration : 0.4272324170595182\n",
      "Cost after 32601 iteration : 0.42702417141480753\n",
      "Cost after 32701 iteration : 0.42681670077953\n",
      "Cost after 32801 iteration : 0.4266100012142192\n",
      "Cost after 32901 iteration : 0.4264040688039902\n",
      "Cost after 33001 iteration : 0.4261988996583621\n",
      "Cost after 33101 iteration : 0.4259944899110831\n",
      "Cost after 33201 iteration : 0.4257908357199568\n",
      "Cost after 33301 iteration : 0.4255879332666694\n",
      "Cost after 33401 iteration : 0.4253857787566182\n",
      "Cost after 33501 iteration : 0.4251843684187426\n",
      "Cost after 33601 iteration : 0.42498369850535506\n",
      "Cost after 33701 iteration : 0.42478376529197365\n",
      "Cost after 33801 iteration : 0.4245845650771567\n",
      "Cost after 33901 iteration : 0.4243860941823379\n",
      "Cost after 34001 iteration : 0.424188348951663\n",
      "Cost after 34101 iteration : 0.42399132575182785\n",
      "Cost after 34201 iteration : 0.42379502097191746\n",
      "Cost after 34301 iteration : 0.4235994310232469\n",
      "Cost after 34401 iteration : 0.42340455233920227\n",
      "Cost after 34501 iteration : 0.4232103813750843\n",
      "Cost after 34601 iteration : 0.42301691460795265\n",
      "Cost after 34701 iteration : 0.4228241485364703\n",
      "Cost after 34801 iteration : 0.42263207968075134\n",
      "Cost after 34901 iteration : 0.42244070458220834\n",
      "Cost after 35001 iteration : 0.4222500198034009\n",
      "Cost after 35101 iteration : 0.42206002192788644\n",
      "Cost after 35201 iteration : 0.42187070756007106\n",
      "Cost after 35301 iteration : 0.4216820733250623\n",
      "Cost after 35401 iteration : 0.4214941158685228\n",
      "Cost after 35501 iteration : 0.42130683185652495\n",
      "Cost after 35601 iteration : 0.4211202179754066\n",
      "Cost after 35701 iteration : 0.42093427093162844\n",
      "Cost after 35801 iteration : 0.42074898745163214\n",
      "Cost after 35901 iteration : 0.4205643642816989\n",
      "Cost after 36001 iteration : 0.4203803981878112\n",
      "Cost after 36101 iteration : 0.42019708595551236\n",
      "Cost after 36201 iteration : 0.4200144243897708\n",
      "Cost after 36301 iteration : 0.41983241031484225\n",
      "Cost after 36401 iteration : 0.4196510405741353\n",
      "Cost after 36501 iteration : 0.4194703120300765\n",
      "Cost after 36601 iteration : 0.4192902215639774\n",
      "Cost after 36701 iteration : 0.41911076607590186\n",
      "Cost after 36801 iteration : 0.41893194248453564\n",
      "Cost after 36901 iteration : 0.4187537477270552\n",
      "Cost after 37001 iteration : 0.4185761787589994\n",
      "Cost after 37101 iteration : 0.4183992325541404\n",
      "Cost after 37201 iteration : 0.4182229061043573\n",
      "Cost after 37301 iteration : 0.4180471964195093\n",
      "Cost after 37401 iteration : 0.41787210052731105\n",
      "Cost after 37501 iteration : 0.4176976154732074\n",
      "Cost after 37601 iteration : 0.4175237383202512\n",
      "Cost after 37701 iteration : 0.4173504661489801\n",
      "Cost after 37801 iteration : 0.41717779605729566\n",
      "Cost after 37901 iteration : 0.4170057251603425\n",
      "Cost after 38001 iteration : 0.4168342505903889\n",
      "Cost after 38101 iteration : 0.4166633694967083\n",
      "Cost after 38201 iteration : 0.4164930790454612\n",
      "Cost after 38301 iteration : 0.41632337641957873\n",
      "Cost after 38401 iteration : 0.4161542588186465\n",
      "Cost after 38501 iteration : 0.4159857234587897\n",
      "Cost after 38601 iteration : 0.4158177675725589\n",
      "Cost after 38701 iteration : 0.41565038840881674\n",
      "Cost after 38801 iteration : 0.41548358323262585\n",
      "Cost after 38901 iteration : 0.4153173493251368\n",
      "Cost after 39001 iteration : 0.41515168398347796\n",
      "Cost after 39101 iteration : 0.4149865845206453\n",
      "Cost after 39201 iteration : 0.4148220482653937\n",
      "Cost after 39301 iteration : 0.4146580725621284\n",
      "Cost after 39401 iteration : 0.41449465477079817\n",
      "Cost after 39501 iteration : 0.4143317922667886\n",
      "Cost after 39601 iteration : 0.4141694824408164\n",
      "Cost after 39701 iteration : 0.41400772269882463\n",
      "Cost after 39801 iteration : 0.41384651046187854\n",
      "Cost after 39901 iteration : 0.41368584316606216\n",
      "Cost after 40001 iteration : 0.41352571826237633\n",
      "Cost after 40101 iteration : 0.4133661332166364\n",
      "Cost after 40201 iteration : 0.41320708550937185\n",
      "Cost after 40301 iteration : 0.4130485726357256\n",
      "Cost after 40401 iteration : 0.412890592105355\n",
      "Cost after 40501 iteration : 0.4127331414423334\n",
      "Cost after 40601 iteration : 0.41257621818505147\n",
      "Cost after 40701 iteration : 0.412419819886121\n",
      "Cost after 40801 iteration : 0.4122639441122779\n",
      "Cost after 40901 iteration : 0.4121085884442869\n",
      "Cost after 41001 iteration : 0.41195375047684607\n",
      "Cost after 41101 iteration : 0.41179942781849344\n",
      "Cost after 41201 iteration : 0.4116456180915128\n",
      "Cost after 41301 iteration : 0.41149231893184135\n",
      "Cost after 41401 iteration : 0.41133952798897716\n",
      "Cost after 41501 iteration : 0.4111872429258883\n",
      "Cost after 41601 iteration : 0.4110354614189219\n",
      "Cost after 41701 iteration : 0.41088418115771397\n",
      "Cost after 41801 iteration : 0.4107333998451005\n",
      "Cost after 41901 iteration : 0.41058311519702845\n",
      "Cost after 42001 iteration : 0.41043332494246776\n",
      "Cost after 42101 iteration : 0.41028402682332454\n",
      "Cost after 42201 iteration : 0.41013521859435387\n",
      "Cost after 42301 iteration : 0.4099868980230738\n",
      "Cost after 42401 iteration : 0.4098390628896802\n",
      "Cost after 42501 iteration : 0.40969171098696233\n",
      "Cost after 42601 iteration : 0.40954484012021825\n",
      "Cost after 42701 iteration : 0.4093984481071714\n",
      "Cost after 42801 iteration : 0.40925253277788837\n",
      "Cost after 42901 iteration : 0.4091070919746961\n",
      "Cost after 43001 iteration : 0.40896212355210043\n",
      "Cost after 43101 iteration : 0.4088176253767053\n",
      "Cost after 43201 iteration : 0.40867359532713265\n",
      "Cost after 43301 iteration : 0.4085300312939418\n",
      "Cost after 43401 iteration : 0.4083869311795514\n",
      "Cost after 43501 iteration : 0.40824429289815983\n",
      "Cost after 43601 iteration : 0.40810211437566796\n",
      "Cost after 43701 iteration : 0.4079603935496016\n",
      "Cost after 43801 iteration : 0.4078191283690344\n",
      "Cost after 43901 iteration : 0.40767831679451205\n",
      "Cost after 44001 iteration : 0.40753795679797605\n",
      "Cost after 44101 iteration : 0.4073980463626892\n",
      "Cost after 44201 iteration : 0.4072585834831609\n",
      "Cost after 44301 iteration : 0.40711956616507267\n",
      "Cost after 44401 iteration : 0.4069809924252055\n",
      "Cost after 44501 iteration : 0.4068428602913661\n",
      "Cost after 44601 iteration : 0.40670516780231564\n",
      "Cost after 44701 iteration : 0.40656791300769657\n",
      "Cost after 44801 iteration : 0.4064310939679626\n",
      "Cost after 44901 iteration : 0.4062947087543071\n",
      "Cost after 45001 iteration : 0.4061587554485937\n",
      "Cost after 45101 iteration : 0.4060232321432854\n",
      "Cost after 45201 iteration : 0.40588813694137643\n",
      "Cost after 45301 iteration : 0.4057534679563234\n",
      "Cost after 45401 iteration : 0.4056192233119765\n",
      "Cost after 45501 iteration : 0.40548540114251247\n",
      "Cost after 45601 iteration : 0.4053519995923673\n",
      "Cost after 45701 iteration : 0.4052190168161694\n",
      "Cost after 45801 iteration : 0.4050864509786735\n",
      "Cost after 45901 iteration : 0.40495430025469503\n",
      "Cost after 46001 iteration : 0.4048225628290449\n",
      "Cost after 46101 iteration : 0.40469123689646463\n",
      "Cost after 46201 iteration : 0.40456032066156206\n",
      "Cost after 46301 iteration : 0.40442981233874803\n",
      "Cost after 46401 iteration : 0.40429971015217264\n",
      "Cost after 46501 iteration : 0.4041700123356621\n",
      "Cost after 46601 iteration : 0.40404071713265743\n",
      "Cost after 46701 iteration : 0.40391182279615123\n",
      "Cost after 46801 iteration : 0.4037833275886272\n",
      "Cost after 46901 iteration : 0.40365522978199875\n",
      "Cost after 47001 iteration : 0.4035275276575481\n",
      "Cost after 47101 iteration : 0.40340021950586674\n",
      "Cost after 47201 iteration : 0.4032733036267953\n",
      "Cost after 47301 iteration : 0.4031467783293645\n",
      "Cost after 47401 iteration : 0.4030206419317362\n",
      "Cost after 47501 iteration : 0.40289489276114493\n",
      "Cost after 47601 iteration : 0.4027695291538403\n",
      "Cost after 47701 iteration : 0.40264454945502903\n",
      "Cost after 47801 iteration : 0.4025199520188181\n",
      "Cost after 47901 iteration : 0.4023957352081576\n",
      "Cost after 48001 iteration : 0.4022718973947848\n",
      "Cost after 48101 iteration : 0.40214843695916835\n",
      "Cost after 48201 iteration : 0.4020253522904525\n",
      "Cost after 48301 iteration : 0.4019026417864021\n",
      "Cost after 48401 iteration : 0.4017803038533477\n",
      "Cost after 48501 iteration : 0.4016583369061316\n",
      "Cost after 48601 iteration : 0.4015367393680541\n",
      "Cost after 48701 iteration : 0.4014155096708192\n",
      "Cost after 48801 iteration : 0.4012946462544821\n",
      "Cost after 48901 iteration : 0.40117414756739644\n",
      "Cost after 49001 iteration : 0.4010540120661617\n",
      "Cost after 49101 iteration : 0.40093423821557117\n",
      "Cost after 49201 iteration : 0.40081482448856076\n",
      "Cost after 49301 iteration : 0.40069576936615714\n",
      "Cost after 49401 iteration : 0.4005770713374272\n",
      "Cost after 49501 iteration : 0.40045872889942796\n",
      "Cost after 49601 iteration : 0.4003407405571552\n",
      "Cost after 49701 iteration : 0.4002231048234953\n",
      "Cost after 49801 iteration : 0.40010582021917424\n",
      "Cost after 49901 iteration : 0.39998888527270965\n",
      "Cost after 50001 iteration : 0.39987229852036144\n",
      "Cost after 50101 iteration : 0.39975605850608364\n",
      "Cost after 50201 iteration : 0.3996401637814766\n",
      "Cost after 50301 iteration : 0.3995246129057387\n",
      "Cost after 50401 iteration : 0.3994094044456197\n",
      "Cost after 50501 iteration : 0.3992945369753731\n",
      "Cost after 50601 iteration : 0.3991800090767099\n",
      "Cost after 50701 iteration : 0.3990658193387521\n",
      "Cost after 50801 iteration : 0.3989519663579866\n",
      "Cost after 50901 iteration : 0.3988384487382194\n",
      "Cost after 51001 iteration : 0.39872526509053074\n",
      "Cost after 51101 iteration : 0.39861241403322956\n",
      "Cost after 51201 iteration : 0.39849989419180903\n",
      "Cost after 51301 iteration : 0.39838770419890174\n",
      "Cost after 51401 iteration : 0.39827584269423627\n",
      "Cost after 51501 iteration : 0.3981643083245928\n",
      "Cost after 51601 iteration : 0.39805309974376013\n",
      "Cost after 51701 iteration : 0.39794221561249216\n",
      "Cost after 51801 iteration : 0.3978316545984648\n",
      "Cost after 51901 iteration : 0.3977214153762342\n",
      "Cost after 52001 iteration : 0.39761149662719364\n",
      "Cost after 52101 iteration : 0.3975018970395323\n",
      "Cost after 52201 iteration : 0.397392615308193\n",
      "Cost after 52301 iteration : 0.3972836501348311\n",
      "Cost after 52401 iteration : 0.3971750002277734\n",
      "Cost after 52501 iteration : 0.3970666643019774\n",
      "Cost after 52601 iteration : 0.3969586410789905\n",
      "Cost after 52701 iteration : 0.3968509292869102\n",
      "Cost after 52801 iteration : 0.39674352766034365\n",
      "Cost after 52901 iteration : 0.39663643494036865\n",
      "Cost after 53001 iteration : 0.39652964987449346\n",
      "Cost after 53101 iteration : 0.3964231712166183\n",
      "Cost after 53201 iteration : 0.39631699772699647\n",
      "Cost after 53301 iteration : 0.39621112817219534\n",
      "Cost after 53401 iteration : 0.3961055613250583\n",
      "Cost after 53501 iteration : 0.39600029596466707\n",
      "Cost after 53601 iteration : 0.3958953308763033\n",
      "Cost after 53701 iteration : 0.39579066485141134\n",
      "Cost after 53801 iteration : 0.3956862966875613\n",
      "Cost after 53901 iteration : 0.39558222518841146\n",
      "Cost after 54001 iteration : 0.39547844916367214\n",
      "Cost after 54101 iteration : 0.3953749674290687\n",
      "Cost after 54201 iteration : 0.3952717788063055\n",
      "Cost after 54301 iteration : 0.3951688821230305\n",
      "Cost after 54401 iteration : 0.39506627621279805\n",
      "Cost after 54501 iteration : 0.39496395991503547\n",
      "Cost after 54601 iteration : 0.39486193207500575\n",
      "Cost after 54701 iteration : 0.39476019154377406\n",
      "Cost after 54801 iteration : 0.3946587371781723\n",
      "Cost after 54901 iteration : 0.39455756784076473\n",
      "Cost after 55001 iteration : 0.3944566823998137\n",
      "Cost after 55101 iteration : 0.3943560797292457\n",
      "Cost after 55201 iteration : 0.3942557587086172\n",
      "Cost after 55301 iteration : 0.3941557182230816\n",
      "Cost after 55401 iteration : 0.39405595716335556\n",
      "Cost after 55501 iteration : 0.3939564744256861\n",
      "Cost after 55601 iteration : 0.39385726891181727\n",
      "Cost after 55701 iteration : 0.39375833952895783\n",
      "Cost after 55801 iteration : 0.3936596851897491\n",
      "Cost after 55901 iteration : 0.3935613048122319\n",
      "Cost after 56001 iteration : 0.39346319731981544\n",
      "Cost after 56101 iteration : 0.393365361641245\n",
      "Cost after 56201 iteration : 0.3932677967105705\n",
      "Cost after 56301 iteration : 0.3931705014671152\n",
      "Cost after 56401 iteration : 0.3930734748554446\n",
      "Cost after 56501 iteration : 0.3929767158253353\n",
      "Cost after 56601 iteration : 0.39288022333174444\n",
      "Cost after 56701 iteration : 0.39278399633477923\n",
      "Cost after 56801 iteration : 0.3926880337996669\n",
      "Cost after 56901 iteration : 0.39259233469672383\n",
      "Cost after 57001 iteration : 0.39249689800132614\n",
      "Cost after 57101 iteration : 0.3924017226938806\n",
      "Cost after 57201 iteration : 0.3923068077597937\n",
      "Cost after 57301 iteration : 0.39221215218944394\n",
      "Cost after 57401 iteration : 0.3921177549781517\n",
      "Cost after 57501 iteration : 0.39202361512615064\n",
      "Cost after 57601 iteration : 0.3919297316385589\n",
      "Cost after 57701 iteration : 0.3918361035253509\n",
      "Cost after 57801 iteration : 0.3917427298013288\n",
      "Cost after 57901 iteration : 0.3916496094860944\n",
      "Cost after 58001 iteration : 0.391556741604021\n",
      "Cost after 58101 iteration : 0.391464125184226\n",
      "Cost after 58201 iteration : 0.3913717592605433\n",
      "Cost after 58301 iteration : 0.3912796428714956\n",
      "Cost after 58401 iteration : 0.39118777506026764\n",
      "Cost after 58501 iteration : 0.39109615487467886\n",
      "Cost after 58601 iteration : 0.39100478136715655\n",
      "Cost after 58701 iteration : 0.39091365359470953\n",
      "Cost after 58801 iteration : 0.39082277061890136\n",
      "Cost after 58901 iteration : 0.3907321315058241\n",
      "Cost after 59001 iteration : 0.3906417353260722\n",
      "Cost after 59101 iteration : 0.39055158115471683\n",
      "Cost after 59201 iteration : 0.3904616680712797\n",
      "Cost after 59301 iteration : 0.3903719951597074\n",
      "Cost after 59401 iteration : 0.3902825615083463\n",
      "Cost after 59501 iteration : 0.3901933662099174\n",
      "Cost after 59601 iteration : 0.39010440836149074\n",
      "Cost after 59701 iteration : 0.3900156870644607\n",
      "Cost after 59801 iteration : 0.3899272014245213\n",
      "Cost after 59901 iteration : 0.38983895055164147\n",
      "Cost after 60001 iteration : 0.3897509335600407\n",
      "Cost after 60101 iteration : 0.3896631495681647\n",
      "Cost after 60201 iteration : 0.3895755976986615\n",
      "Cost after 60301 iteration : 0.38948827707835704\n",
      "Cost after 60401 iteration : 0.3894011868382315\n",
      "Cost after 60501 iteration : 0.3893143261133963\n",
      "Cost after 60601 iteration : 0.3892276940430696\n",
      "Cost after 60701 iteration : 0.38914128977055357\n",
      "Cost after 60801 iteration : 0.3890551124432112\n",
      "Cost after 60901 iteration : 0.38896916121244307\n",
      "Cost after 61001 iteration : 0.38888343523366437\n",
      "Cost after 61101 iteration : 0.38879793366628246\n",
      "Cost after 61201 iteration : 0.38871265567367436\n",
      "Cost after 61301 iteration : 0.38862760042316363\n",
      "Cost after 61401 iteration : 0.3885427670859992\n",
      "Cost after 61501 iteration : 0.38845815483733204\n",
      "Cost after 61601 iteration : 0.388373762856194\n",
      "Cost after 61701 iteration : 0.38828959032547583\n",
      "Cost after 61801 iteration : 0.38820563643190464\n",
      "Cost after 61901 iteration : 0.38812190036602384\n",
      "Cost after 62001 iteration : 0.3880383813221702\n",
      "Cost after 62101 iteration : 0.3879550784984536\n",
      "Cost after 62201 iteration : 0.3878719910967353\n",
      "Cost after 62301 iteration : 0.38778911832260704\n",
      "Cost after 62401 iteration : 0.3877064593853706\n",
      "Cost after 62501 iteration : 0.38762401349801634\n",
      "Cost after 62601 iteration : 0.3875417798772029\n",
      "Cost after 62701 iteration : 0.38745975774323704\n",
      "Cost after 62801 iteration : 0.38737794632005296\n",
      "Cost after 62901 iteration : 0.38729634483519165\n",
      "Cost after 63001 iteration : 0.38721495251978194\n",
      "Cost after 63101 iteration : 0.3871337686085196\n",
      "Cost after 63201 iteration : 0.3870527923396477\n",
      "Cost after 63301 iteration : 0.38697202295493704\n",
      "Cost after 63401 iteration : 0.3868914596996669\n",
      "Cost after 63501 iteration : 0.38681110182260453\n",
      "Cost after 63601 iteration : 0.3867309485759872\n",
      "Cost after 63701 iteration : 0.38665099921550217\n",
      "Cost after 63801 iteration : 0.38657125300026746\n",
      "Cost after 63901 iteration : 0.3864917091928136\n",
      "Cost after 64001 iteration : 0.3864123670590642\n",
      "Cost after 64101 iteration : 0.38633322586831764\n",
      "Cost after 64201 iteration : 0.3862542848932281\n",
      "Cost after 64301 iteration : 0.38617554340978716\n",
      "Cost after 64401 iteration : 0.386097000697306\n",
      "Cost after 64501 iteration : 0.3860186560383963\n",
      "Cost after 64601 iteration : 0.3859405087189525\n",
      "Cost after 64701 iteration : 0.38586255802813424\n",
      "Cost after 64801 iteration : 0.3857848032583478\n",
      "Cost after 64901 iteration : 0.3857072437052284\n",
      "Cost after 65001 iteration : 0.385629878667623\n",
      "Cost after 65101 iteration : 0.38555270744757225\n",
      "Cost after 65201 iteration : 0.3854757293502931\n",
      "Cost after 65301 iteration : 0.38539894368416217\n",
      "Cost after 65401 iteration : 0.3853223497606973\n",
      "Cost after 65501 iteration : 0.3852459468945414\n",
      "Cost after 65601 iteration : 0.38516973440344515\n",
      "Cost after 65701 iteration : 0.38509371160825\n",
      "Cost after 65801 iteration : 0.38501787783287156\n",
      "Cost after 65901 iteration : 0.38494223240428277\n",
      "Cost after 66001 iteration : 0.3848667746524972\n",
      "Cost after 66101 iteration : 0.3847915039105529\n",
      "Cost after 66201 iteration : 0.3847164195144958\n",
      "Cost after 66301 iteration : 0.38464152080336356\n",
      "Cost after 66401 iteration : 0.38456680711916924\n",
      "Cost after 66501 iteration : 0.3844922778068854\n",
      "Cost after 66601 iteration : 0.38441793221442777\n",
      "Cost after 66701 iteration : 0.38434376969264006\n",
      "Cost after 66801 iteration : 0.3842697895952776\n",
      "Cost after 66901 iteration : 0.3841959912789917\n",
      "Cost after 67001 iteration : 0.3841223741033145\n",
      "Cost after 67101 iteration : 0.3840489374306431\n",
      "Cost after 67201 iteration : 0.3839756806262244\n",
      "Cost after 67301 iteration : 0.38390260305813956\n",
      "Cost after 67401 iteration : 0.383829704097289\n",
      "Cost after 67501 iteration : 0.3837569831173773\n",
      "Cost after 67601 iteration : 0.3836844394948984\n",
      "Cost after 67701 iteration : 0.3836120726091201\n",
      "Cost after 67801 iteration : 0.3835398818420698\n",
      "Cost after 67901 iteration : 0.3834678665785196\n",
      "Cost after 68001 iteration : 0.3833960262059717\n",
      "Cost after 68101 iteration : 0.3833243601146436\n",
      "Cost after 68201 iteration : 0.3832528676974539\n",
      "Cost after 68301 iteration : 0.3831815483500082\n",
      "Cost after 68401 iteration : 0.38311040147058434\n",
      "Cost after 68501 iteration : 0.38303942646011807\n",
      "Cost after 68601 iteration : 0.38296862272218957\n",
      "Cost after 68701 iteration : 0.3828979896630094\n",
      "Cost after 68801 iteration : 0.3828275266914039\n",
      "Cost after 68901 iteration : 0.38275723321880195\n",
      "Cost after 69001 iteration : 0.38268710865922095\n",
      "Cost after 69101 iteration : 0.3826171524292532\n",
      "Cost after 69201 iteration : 0.38254736394805255\n",
      "Cost after 69301 iteration : 0.3824777426373203\n",
      "Cost after 69401 iteration : 0.3824082879212926\n",
      "Cost after 69501 iteration : 0.3823389992267264\n",
      "Cost after 69601 iteration : 0.3822698759828865\n",
      "Cost after 69701 iteration : 0.3822009176215324\n",
      "Cost after 69801 iteration : 0.3821321235769051\n",
      "Cost after 69901 iteration : 0.38206349328571415\n",
      "Cost after 70001 iteration : 0.3819950261871247\n",
      "Cost after 70101 iteration : 0.3819267217227444\n",
      "Cost after 70201 iteration : 0.3818585793366111\n",
      "Cost after 70301 iteration : 0.38179059847518\n",
      "Cost after 70401 iteration : 0.3817227785873105\n",
      "Cost after 70501 iteration : 0.38165511912425454\n",
      "Cost after 70601 iteration : 0.3815876195396432\n",
      "Cost after 70701 iteration : 0.3815202792894751\n",
      "Cost after 70801 iteration : 0.3814530978321035\n",
      "Cost after 70901 iteration : 0.38138607462822444\n",
      "Cost after 71001 iteration : 0.38131920914086437\n",
      "Cost after 71101 iteration : 0.381252500835368\n",
      "Cost after 71201 iteration : 0.3811859491793864\n",
      "Cost after 71301 iteration : 0.38111955364286515\n",
      "Cost after 71401 iteration : 0.381053313698032\n",
      "Cost after 71501 iteration : 0.38098722881938574\n",
      "Cost after 71601 iteration : 0.38092129848368367\n",
      "Cost after 71701 iteration : 0.38085552216993074\n",
      "Cost after 71801 iteration : 0.38078989935936736\n",
      "Cost after 71901 iteration : 0.38072442953545804\n",
      "Cost after 72001 iteration : 0.38065911218388004\n",
      "Cost after 72101 iteration : 0.3805939467925118\n",
      "Cost after 72201 iteration : 0.38052893285142175\n",
      "Cost after 72301 iteration : 0.3804640698528572\n",
      "Cost after 72401 iteration : 0.3803993572912325\n",
      "Cost after 72501 iteration : 0.3803347946631187\n",
      "Cost after 72601 iteration : 0.38027038146723224\n",
      "Cost after 72701 iteration : 0.38020611720442365\n",
      "Cost after 72801 iteration : 0.38014200137766696\n",
      "Cost after 72901 iteration : 0.38007803349204883\n",
      "Cost after 73001 iteration : 0.3800142130547575\n",
      "Cost after 73101 iteration : 0.37995053957507235\n",
      "Cost after 73201 iteration : 0.3798870125643531\n",
      "Cost after 73301 iteration : 0.37982363153602877\n",
      "Cost after 73401 iteration : 0.3797603960055885\n",
      "Cost after 73501 iteration : 0.37969730549056924\n",
      "Cost after 73601 iteration : 0.37963435951054686\n",
      "Cost after 73701 iteration : 0.3795715575871248\n",
      "Cost after 73801 iteration : 0.3795088992439242\n",
      "Cost after 73901 iteration : 0.379446384006574\n",
      "Cost after 74001 iteration : 0.3793840114026997\n",
      "Cost after 74101 iteration : 0.3793217809619145\n",
      "Cost after 74201 iteration : 0.37925969221580835\n",
      "Cost after 74301 iteration : 0.3791977446979385\n",
      "Cost after 74401 iteration : 0.37913593794381933\n",
      "Cost after 74501 iteration : 0.37907427149091216\n",
      "Cost after 74601 iteration : 0.379012744878616\n",
      "Cost after 74701 iteration : 0.3789513576482577\n",
      "Cost after 74801 iteration : 0.37889010934308187\n",
      "Cost after 74901 iteration : 0.37882899950824134\n",
      "Cost after 75001 iteration : 0.378768027690788\n",
      "Cost after 75101 iteration : 0.37870719343966275\n",
      "Cost after 75201 iteration : 0.3786464963056861\n",
      "Cost after 75301 iteration : 0.3785859358415491\n",
      "Cost after 75401 iteration : 0.3785255116018034\n",
      "Cost after 75501 iteration : 0.3784652231428529\n",
      "Cost after 75601 iteration : 0.37840507002294305\n",
      "Cost after 75701 iteration : 0.3783450518021528\n",
      "Cost after 75801 iteration : 0.3782851680423853\n",
      "Cost after 75901 iteration : 0.3782254183073583\n",
      "Cost after 76001 iteration : 0.3781658021625954\n",
      "Cost after 76101 iteration : 0.3781063191754172\n",
      "Cost after 76201 iteration : 0.3780469689149322\n",
      "Cost after 76301 iteration : 0.3779877509520278\n",
      "Cost after 76401 iteration : 0.37792866485936133\n",
      "Cost after 76501 iteration : 0.3778697102113522\n",
      "Cost after 76601 iteration : 0.37781088658417183\n",
      "Cost after 76701 iteration : 0.3777521935557359\n",
      "Cost after 76801 iteration : 0.37769363070569534\n",
      "Cost after 76901 iteration : 0.3776351976154277\n",
      "Cost after 77001 iteration : 0.37757689386802884\n",
      "Cost after 77101 iteration : 0.37751871904830453\n",
      "Cost after 77201 iteration : 0.37746067274276146\n",
      "Cost after 77301 iteration : 0.37740275453959926\n",
      "Cost after 77401 iteration : 0.3773449640287022\n",
      "Cost after 77501 iteration : 0.377287300801631\n",
      "Cost after 77601 iteration : 0.37722976445161377\n",
      "Cost after 77701 iteration : 0.377172354573539\n",
      "Cost after 77801 iteration : 0.3771150707639465\n",
      "Cost after 77901 iteration : 0.3770579126210196\n",
      "Cost after 78001 iteration : 0.3770008797445774\n",
      "Cost after 78101 iteration : 0.3769439717360661\n",
      "Cost after 78201 iteration : 0.3768871881985515\n",
      "Cost after 78301 iteration : 0.3768305287367111\n",
      "Cost after 78401 iteration : 0.37677399295682595\n",
      "Cost after 78501 iteration : 0.3767175804667728\n",
      "Cost after 78601 iteration : 0.3766612908760168\n",
      "Cost after 78701 iteration : 0.3766051237956031\n",
      "Cost after 78801 iteration : 0.37654907883814986\n",
      "Cost after 78901 iteration : 0.3764931556178396\n",
      "Cost after 79001 iteration : 0.37643735375041276\n",
      "Cost after 79101 iteration : 0.37638167285315915\n",
      "Cost after 79201 iteration : 0.3763261125449112\n",
      "Cost after 79301 iteration : 0.3762706724460357\n",
      "Cost after 79401 iteration : 0.37621535217842694\n",
      "Cost after 79501 iteration : 0.37616015136549935\n",
      "Cost after 79601 iteration : 0.37610506963217955\n",
      "Cost after 79701 iteration : 0.37605010660489935\n",
      "Cost after 79801 iteration : 0.37599526191158916\n",
      "Cost after 79901 iteration : 0.37594053518166937\n",
      "Cost after 80001 iteration : 0.37588592604604426\n",
      "Cost after 80101 iteration : 0.3758314341370946\n",
      "Cost after 80201 iteration : 0.37577705908867\n",
      "Cost after 80301 iteration : 0.37572280053608276\n",
      "Cost after 80401 iteration : 0.37566865811609995\n",
      "Cost after 80501 iteration : 0.3756146314669372\n",
      "Cost after 80601 iteration : 0.3755607202282508\n",
      "Cost after 80701 iteration : 0.37550692404113195\n",
      "Cost after 80801 iteration : 0.3754532425480987\n",
      "Cost after 80901 iteration : 0.37539967539309\n",
      "Cost after 81001 iteration : 0.3753462222214585\n",
      "Cost after 81101 iteration : 0.3752928826799639\n",
      "Cost after 81201 iteration : 0.37523965641676615\n",
      "Cost after 81301 iteration : 0.3751865430814186\n",
      "Cost after 81401 iteration : 0.37513354232486185\n",
      "Cost after 81501 iteration : 0.37508065379941663\n",
      "Cost after 81601 iteration : 0.3750278771587777\n",
      "Cost after 81701 iteration : 0.37497521205800655\n",
      "Cost after 81801 iteration : 0.3749226581535257\n",
      "Cost after 81901 iteration : 0.37487021510311197\n",
      "Cost after 82001 iteration : 0.3748178825658897\n",
      "Cost after 82101 iteration : 0.3747656602023248\n",
      "Cost after 82201 iteration : 0.3747135476742184\n",
      "Cost after 82301 iteration : 0.3746615446447\n",
      "Cost after 82401 iteration : 0.3746096507782216\n",
      "Cost after 82501 iteration : 0.3745578657405517\n",
      "Cost after 82601 iteration : 0.3745061891987683\n",
      "Cost after 82701 iteration : 0.37445462082125364\n",
      "Cost after 82801 iteration : 0.37440316027768694\n",
      "Cost after 82901 iteration : 0.37435180723903955\n",
      "Cost after 83001 iteration : 0.3743005613775676\n",
      "Cost after 83101 iteration : 0.3742494223668072\n",
      "Cost after 83201 iteration : 0.3741983898815675\n",
      "Cost after 83301 iteration : 0.37414746359792467\n",
      "Cost after 83401 iteration : 0.3740966431932168\n",
      "Cost after 83501 iteration : 0.374045928346037\n",
      "Cost after 83601 iteration : 0.37399531873622827\n",
      "Cost after 83701 iteration : 0.3739448140448772\n",
      "Cost after 83801 iteration : 0.3738944139543084\n",
      "Cost after 83901 iteration : 0.3738441181480783\n",
      "Cost after 84001 iteration : 0.37379392631096975\n",
      "Cost after 84101 iteration : 0.37374383812898654\n",
      "Cost after 84201 iteration : 0.37369385328934684\n",
      "Cost after 84301 iteration : 0.3736439714804785\n",
      "Cost after 84401 iteration : 0.3735941923920129\n",
      "Cost after 84501 iteration : 0.37354451571477915\n",
      "Cost after 84601 iteration : 0.37349494114079895\n",
      "Cost after 84701 iteration : 0.3734454683632811\n",
      "Cost after 84801 iteration : 0.3733960970766153\n",
      "Cost after 84901 iteration : 0.3733468269763675\n",
      "Cost after 85001 iteration : 0.37329765775927387\n",
      "Cost after 85101 iteration : 0.37324858912323583\n",
      "Cost after 85201 iteration : 0.373199620767314\n",
      "Cost after 85301 iteration : 0.3731507523917236\n",
      "Cost after 85401 iteration : 0.37310198369782843\n",
      "Cost after 85501 iteration : 0.37305331438813616\n",
      "Cost after 85601 iteration : 0.3730047441662925\n",
      "Cost after 85701 iteration : 0.3729562727370763\n",
      "Cost after 85801 iteration : 0.3729078998063945\n",
      "Cost after 85901 iteration : 0.3728596250812762\n",
      "Cost after 86001 iteration : 0.37281144826986806\n",
      "Cost after 86101 iteration : 0.3727633690814294\n",
      "Cost after 86201 iteration : 0.37271538722632636\n",
      "Cost after 86301 iteration : 0.3726675024160274\n",
      "Cost after 86401 iteration : 0.3726197143630981\n",
      "Cost after 86501 iteration : 0.3725720227811957\n",
      "Cost after 86601 iteration : 0.3725244273850648\n",
      "Cost after 86701 iteration : 0.37247692789053194\n",
      "Cost after 86801 iteration : 0.3724295240145007\n",
      "Cost after 86901 iteration : 0.37238221547494693\n",
      "Cost after 87001 iteration : 0.37233500199091374\n",
      "Cost after 87101 iteration : 0.37228788328250634\n",
      "Cost after 87201 iteration : 0.37224085907088805\n",
      "Cost after 87301 iteration : 0.3721939290782743\n",
      "Cost after 87401 iteration : 0.372147093027929\n",
      "Cost after 87501 iteration : 0.3721003506441587\n",
      "Cost after 87601 iteration : 0.3720537016523089\n",
      "Cost after 87701 iteration : 0.37200714577875826\n",
      "Cost after 87801 iteration : 0.37196068275091504\n",
      "Cost after 87901 iteration : 0.3719143122972112\n",
      "Cost after 88001 iteration : 0.37186803414709885\n",
      "Cost after 88101 iteration : 0.371821848031045\n",
      "Cost after 88201 iteration : 0.37177575368052707\n",
      "Cost after 88301 iteration : 0.3717297508280285\n",
      "Cost after 88401 iteration : 0.37168383920703413\n",
      "Cost after 88501 iteration : 0.3716380185520255\n",
      "Cost after 88601 iteration : 0.37159228859847654\n",
      "Cost after 88701 iteration : 0.37154664908284885\n",
      "Cost after 88801 iteration : 0.3715010997425879\n",
      "Cost after 88901 iteration : 0.3714556403161176\n",
      "Cost after 89001 iteration : 0.3714102705428369\n",
      "Cost after 89101 iteration : 0.3713649901631146\n",
      "Cost after 89201 iteration : 0.3713197989182854\n",
      "Cost after 89301 iteration : 0.37127469655064566\n",
      "Cost after 89401 iteration : 0.37122968280344876\n",
      "Cost after 89501 iteration : 0.37118475742090096\n",
      "Cost after 89601 iteration : 0.3711399201481572\n",
      "Cost after 89701 iteration : 0.37109517073131687\n",
      "Cost after 89801 iteration : 0.3710505089174193\n",
      "Cost after 89901 iteration : 0.37100593445443997\n",
      "Cost after 90001 iteration : 0.370961447091286\n",
      "Cost after 90101 iteration : 0.3709170465777921\n",
      "Cost after 90201 iteration : 0.37087273266471676\n",
      "Cost after 90301 iteration : 0.37082850510373727\n",
      "Cost after 90401 iteration : 0.37078436364744666\n",
      "Cost after 90501 iteration : 0.3707403080493489\n",
      "Cost after 90601 iteration : 0.37069633806385516\n",
      "Cost after 90701 iteration : 0.37065245344627984\n",
      "Cost after 90801 iteration : 0.3706086539528363\n",
      "Cost after 90901 iteration : 0.3705649393406329\n",
      "Cost after 91001 iteration : 0.37052130936766947\n",
      "Cost after 91101 iteration : 0.370477763792833\n",
      "Cost after 91201 iteration : 0.3704343023758931\n",
      "Cost after 91301 iteration : 0.3703909248774997\n",
      "Cost after 91401 iteration : 0.3703476310591775\n",
      "Cost after 91501 iteration : 0.3703044206833232\n",
      "Cost after 91601 iteration : 0.37026129351320086\n",
      "Cost after 91701 iteration : 0.370218249312939\n",
      "Cost after 91801 iteration : 0.37017528784752574\n",
      "Cost after 91901 iteration : 0.370132408882806\n",
      "Cost after 92001 iteration : 0.37008961218547715\n",
      "Cost after 92101 iteration : 0.37004689752308495\n",
      "Cost after 92201 iteration : 0.37000426466402075\n",
      "Cost after 92301 iteration : 0.3699617133775172\n",
      "Cost after 92401 iteration : 0.36991924343364446\n",
      "Cost after 92501 iteration : 0.3698768546033069\n",
      "Cost after 92601 iteration : 0.3698345466582392\n",
      "Cost after 92701 iteration : 0.3697923193710027\n",
      "Cost after 92801 iteration : 0.36975017251498177\n",
      "Cost after 92901 iteration : 0.3697081058643806\n",
      "Cost after 93001 iteration : 0.36966611919421916\n",
      "Cost after 93101 iteration : 0.36962421228032954\n",
      "Cost after 93201 iteration : 0.3695823848993531\n",
      "Cost after 93301 iteration : 0.36954063682873617\n",
      "Cost after 93401 iteration : 0.3694989678467272\n",
      "Cost after 93501 iteration : 0.36945737773237264\n",
      "Cost after 93601 iteration : 0.36941586626551404\n",
      "Cost after 93701 iteration : 0.369374433226784\n",
      "Cost after 93801 iteration : 0.36933307839760326\n",
      "Cost after 93901 iteration : 0.3692918015601774\n",
      "Cost after 94001 iteration : 0.36925060249749253\n",
      "Cost after 94101 iteration : 0.3692094809933129\n",
      "Cost after 94201 iteration : 0.369168436832177\n",
      "Cost after 94301 iteration : 0.3691274697993945\n",
      "Cost after 94401 iteration : 0.36908657968104247\n",
      "Cost after 94501 iteration : 0.3690457662639628\n",
      "Cost after 94601 iteration : 0.369005029335758\n",
      "Cost after 94701 iteration : 0.36896436868478844\n",
      "Cost after 94801 iteration : 0.3689237841001694\n",
      "Cost after 94901 iteration : 0.36888327537176724\n",
      "Cost after 95001 iteration : 0.368842842290196\n",
      "Cost after 95101 iteration : 0.3688024846468149\n",
      "Cost after 95201 iteration : 0.3687622022337249\n",
      "Cost after 95301 iteration : 0.36872199484376517\n",
      "Cost after 95401 iteration : 0.3686818622705101\n",
      "Cost after 95501 iteration : 0.3686418043082665\n",
      "Cost after 95601 iteration : 0.3686018207520698\n",
      "Cost after 95701 iteration : 0.36856191139768146\n",
      "Cost after 95801 iteration : 0.3685220760415858\n",
      "Cost after 95901 iteration : 0.3684823144809866\n",
      "Cost after 96001 iteration : 0.3684426265138044\n",
      "Cost after 96101 iteration : 0.368403011938673\n",
      "Cost after 96201 iteration : 0.3683634705549369\n",
      "Cost after 96301 iteration : 0.3683240021626481\n",
      "Cost after 96401 iteration : 0.36828460656256273\n",
      "Cost after 96501 iteration : 0.3682452835561388\n",
      "Cost after 96601 iteration : 0.3682060329455324\n",
      "Cost after 96701 iteration : 0.3681668545335952\n",
      "Cost after 96801 iteration : 0.3681277481238714\n",
      "Cost after 96901 iteration : 0.3680887135205949\n",
      "Cost after 97001 iteration : 0.3680497505286862\n",
      "Cost after 97101 iteration : 0.3680108589537494\n",
      "Cost after 97201 iteration : 0.3679720386020697\n",
      "Cost after 97301 iteration : 0.36793328928061\n",
      "Cost after 97401 iteration : 0.3678946107970086\n",
      "Cost after 97501 iteration : 0.36785600295957566\n",
      "Cost after 97601 iteration : 0.3678174655772912\n",
      "Cost after 97701 iteration : 0.36777899845980155\n",
      "Cost after 97801 iteration : 0.3677406014174168\n",
      "Cost after 97901 iteration : 0.3677022742611081\n",
      "Cost after 98001 iteration : 0.36766401680250477\n",
      "Cost after 98101 iteration : 0.3676258288538915\n",
      "Cost after 98201 iteration : 0.36758771022820574\n",
      "Cost after 98301 iteration : 0.3675496607390347\n",
      "Cost after 98401 iteration : 0.36751168020061287\n",
      "Cost after 98501 iteration : 0.3674737684278194\n",
      "Cost after 98601 iteration : 0.3674359252361747\n",
      "Cost after 98701 iteration : 0.36739815044183877\n",
      "Cost after 98801 iteration : 0.36736044386160777\n",
      "Cost after 98901 iteration : 0.3673228053129116\n",
      "Cost after 99001 iteration : 0.36728523461381135\n",
      "Cost after 99101 iteration : 0.3672477315829964\n",
      "Cost after 99201 iteration : 0.36721029603978195\n",
      "Cost after 99301 iteration : 0.36717292780410665\n",
      "Cost after 99401 iteration : 0.36713562669652955\n",
      "Cost after 99501 iteration : 0.36709839253822785\n",
      "Cost after 99601 iteration : 0.367061225150994\n",
      "Cost after 99701 iteration : 0.3670241243572336\n",
      "Cost after 99801 iteration : 0.3669870899799623\n",
      "Cost after 99901 iteration : 0.36695012184280384\n"
     ]
    }
   ],
   "source": [
    "W, b, costs = train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot costs to see how our model was converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation\n",
    "Let's check accuracy on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 84.51219512195122 %\n",
      "Test accuracy: 79.02439024390245 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(predict(W, b, X_train) - Y_train)) * 100))\n",
    "print(\"Test accuracy: {} %\".format(100 - np.mean(np.abs(predict(W, b, X_test) - Y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Increasing the number of iterations can improve training accuracy, but there's a risk of overfitting. Overfitting occurs when the model learns to fit the training data too closely, capturing noise or irrelevant patterns that don't generalize well to unseen data. In such cases, while the training accuracy continues to increase, the test accuracy may plateau or even decrease.\n",
    "\n",
    "To address overfitting, techniques like regularization and model complexity reduction are employed. Additionally, the transition to deep neural networks offers more sophisticated methods for improving accuracies, even in the presence of overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
